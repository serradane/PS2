

Serra Dane


Understanding Bias of the Machine Learning Approaches


Machine learning algorithms have been widely embraced last few decades. Nevertheless, do we all know how machine learning works? Machine learning algorithms build a model based on sample data, known as training data, to make predictions or decisions without being explicitly programmed to do so. Furthermore, most of us did not know that there is also a term called "bias" in machine learning. In 1908, Mitchell came up with a definition for it, "Any basis for choosing one generalization (hypothesis) over another, other than strict consistency with the observed training instances." (Mitchell, 1980). Four years ago, a researcher at a New York start-up noticed that the artificial intelligence system she was developing was blatantly biased against Black people. Soon after, a Black researcher in Boston discovered that an artificial intelligence system could not recognize her face unless she wore a white mask. The Harvard Business Review also mentions that word embedding systems might frequently associate 'man' with 'doctor' and 'woman' with 'nurse.' By looking at those results of the machine learning algorithms, we can say that they most likely include such biases in several ways, which most people and even programmers do not recognize or mind. However, this is important because machine learning algorithms have a great voice in today's world that we are trying to make unbiased and equal in every means. 

Considering the Mitchell definition of "bias" again, one can say that certain dataset elements are more heavily weighted or represented than others. Also, Dietterich states that every exploratory learning algorithm must adopt a bias to generalize beyond the training data (Dietterich, 1995). However, this does not mean that the outputs of those algorithms cannot be unbiased. The term bias, which we understand as prejudice in favor of or against one thing, person, or group compared with another, depends only on the datasets that the programmer inputs to the algorithms, not on the models that can learn only by creating a biased understanding of the dataset. We can categorize machine learning bias into several types: racial bias, gender bias, sample bias, exclusion bias, and others. We all know that some of those biases have a history dating back centuries in every culture. As we introduce machine learning algorithms, we hand the biases we have in the input datasets. One of the machine learning biases is racial bias (International, 2021). It occurs when data favors specific demographics. This bias is evident in facial recognition and automated voice recognition technology, which fail to distinguish people of color as accurately as Caucasians. Another one is exclusion bias which is particularly prevalent during the data preprocessing stage. Most of the time, valuable material is deleted because it is deemed insignificant. It can, however, emerge due to the systematic exclusion of certain information. Assume one has a dataset of client sales in the United States and Canada. Because 98% of the consumers are from America, one decides to erase the location data as it is unimportant. However, the model will miss that its Canadian consumers spend twice as much.


